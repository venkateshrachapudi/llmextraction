{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Enhanced LLM-based PDF Extraction (Multiple Permits, Stdlib Only)\nThis notebook extracts **multiple permit JSON objects** from a PDF with no external installs.\n\n- Stdlib-only PDF parser (zlib + regex).\n- Handles free-text and tabular formats.\n- Uses LLM to normalize field names and values into a canonical schema.\n- Returns an array of JSON objects (one per permit).\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "\nimport os, re, zlib, json\nimport openai\n\nSCHEMA = [\"Permit Number\", \"Issue Date\", \"Expiry Date\", \"Owner Name\", \"Address\"]\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "\ndef _extract_strings_from_TJ_array(arr: str) -> str:\n    out = []\n    i, n = 0, len(arr)\n    while i < n:\n        if arr[i] == '(':\n            i += 1; buf = []; depth = 1; esc = False\n            while i < n and depth > 0:\n                c = arr[i]\n                if esc: buf.append(c); esc = False\n                else:\n                    if c == '\\\\': esc = True\n                    elif c == '(':\n                        depth += 1; buf.append(c)\n                    elif c == ')':\n                        depth -= 1\n                        if depth == 0: break\n                        buf.append(c)\n                    else: buf.append(c)\n                i += 1\n            out.append(''.join(buf))\n        else: i += 1\n    return ''.join(out)\n\ndef _extract_strings_parens(s: str) -> str:\n    out = []\n    i, n = 0, len(s)\n    while i < n:\n        if s[i] == '(':\n            i += 1; buf = []; depth = 1; esc = False\n            while i < n and depth > 0:\n                c = s[i]\n                if esc: buf.append(c); esc = False\n                else:\n                    if c == '\\\\': esc = True\n                    elif c == '(':\n                        depth += 1; buf.append(c)\n                    elif c == ')':\n                        depth -= 1\n                        if depth == 0: break\n                        buf.append(c)\n                    else: buf.append(c)\n                i += 1\n            out.append(''.join(buf))\n        else: i += 1\n    return ' '.join(out)\n\ndef _try_inflate(data: bytes) -> bytes:\n    try: return zlib.decompress(data)\n    except Exception: return data\n\ndef extract_raw_text(pdf_path: str) -> str:\n    with open(pdf_path, \"rb\") as f:\n        raw = f.read()\n    text_chunks = []\n    for m in re.finditer(br\"stream[\\r\\n]+(.*?)[\\r\\n]+endstream\", raw, flags=re.DOTALL):\n        inflated = _try_inflate(m.group(1))\n        try: s = inflated.decode(\"latin-1\", errors=\"ignore\")\n        except Exception: continue\n        for bt in re.finditer(r\"BT(.*?)ET\", s, flags=re.DOTALL):\n            body = bt.group(1)\n            for tj in re.finditer(r\"\\((?:\\\\.|[^\\)])*\\)\\s*Tj\", body):\n                text_chunks.append(_extract_strings_parens(tj.group(0)))\n            for tja in re.finditer(r\"\\[(.*?)\\]\\s*TJ\", body, flags=re.DOTALL):\n                text_chunks.append(_extract_strings_from_TJ_array(tja.group(1)))\n    if not text_chunks:\n        try:\n            s_all = raw.decode(\"latin-1\", errors=\"ignore\")\n            for tj in re.finditer(r\"\\((?:\\\\.|[^\\)])*\\)\\s*Tj\", s_all):\n                text_chunks.append(_extract_strings_parens(tj.group(0)))\n        except Exception: pass\n    return re.sub(r\"\\s+\", \" \", \" \".join(text_chunks)).strip()\n\ndef split_blocks(text):\n    return [b.strip() for b in text.split(\"\\n\\n\") if b.strip()]\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "\ndef llm_extract_permits(block, model=\"gpt-4o-mini\"):\n    prompt = f\"\"\"\n    You are an information extractor. Extract permits into this schema:\n\n    {SCHEMA}\n\n    Input block:\n    {block}\n\n    If multiple permits are present (e.g., table rows), \n    return a JSON array with one object per permit.\n    If only one, return an array with one object.\n    If none, return [].\n    \"\"\"\n    resp = openai.ChatCompletion.create(\n        model=model,\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a precise data extraction assistant.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        temperature=0\n    )\n    try:\n        data = json.loads(resp[\"choices\"][0][\"message\"][\"content\"])\n        if isinstance(data, dict):\n            return [data]\n        return data\n    except Exception:\n        return []\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "\ndef extract_all_permits(pdf_path):\n    text = extract_raw_text(pdf_path)\n    blocks = split_blocks(text)\n    all_permits = []\n    for block in blocks:\n        permits = llm_extract_permits(block)\n        if permits:\n            all_permits.extend(permits)\n    return all_permits\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "\npdf_path = \"/mnt/data/permit_table_example.pdf\"  # Replace with your PDF path\npermits = extract_all_permits(pdf_path)\nprint(json.dumps(permits, indent=2))\n\nwith open(\"/mnt/data/permits_extracted.json\", \"w\") as f:\n    json.dump(permits, f, indent=2)\nprint(\"Saved -> /mnt/data/permits_extracted.json\")\n"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}